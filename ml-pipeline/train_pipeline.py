from data_preparation import CattleDataProcessor
from model_architecture import CattleWeightPredictor, ModelEnsemble
import numpy as np
import tensorflow as tf
import json
from pathlib import Path
import matplotlib.pyplot as plt
import pandas as pd

class TrainingPipeline:
    def __init__(self, data_dir="processed_data"):
        self.data_dir = Path(data_dir)
        self.models = {}
        
    def load_processed_data(self):
        """Ä°ÅŸlenmiÅŸ veriyi yÃ¼kle"""
        print("ğŸ“‚ Ä°ÅŸlenmiÅŸ veri yÃ¼kleniyor...")
        
        data = {}
        for split in ['train', 'val', 'test']:
            X = np.load(self.data_dir / f"X_{split}.npy")
            y = np.load(self.data_dir / f"y_{split}.npy")
            
            with open(self.data_dir / f"metadata_{split}.json", 'r') as f:
                metadata = json.load(f)
            
            data[split] = (X, y, metadata)
            print(f"âœ… {split.capitalize()} set: {X.shape[0]} Ã¶rnek yÃ¼klendi")
        
        return data
    
    def train_multiple_models(self, data, architectures=['resnet50', 'efficientnet', 'custom_cnn']):
        """Birden fazla model mimarisi eÄŸit"""
        print("ğŸš€ Ã‡oklu model eÄŸitimi baÅŸlatÄ±lÄ±yor...")
        
        X_train, y_train, _ = data['train']
        X_val, y_val, _ = data['val']
        X_test, y_test, _ = data['test']
        
        results = {}
        
        for arch in architectures:
            print(f"\nğŸ”¥ {arch.upper()} modeli eÄŸitiliyor...")
            
            # Model oluÅŸtur
            predictor = CattleWeightPredictor()
            predictor.model = predictor.create_model(architecture=arch)
            
            # EÄŸit
            history = predictor.train_model(
                X_train, y_train, X_val, y_val,
                epochs=50, batch_size=32
            )
            
            # Fine-tuning (transfer learning iÃ§in)
            if arch in ['resnet50', 'efficientnet']:
                print(f"ğŸ”§ {arch} fine-tuning...")
                predictor.fine_tune_model(X_train, y_train, X_val, y_val, epochs=20)
            
            # DeÄŸerlendir
            metrics, predictions = predictor.evaluate_model(X_test, y_test)
            
            # Kaydet
            model_path = f"models/cattle_weight_{arch}.h5"
            Path("models").mkdir(exist_ok=True)
            predictor.save_model(model_path)
            
            # SonuÃ§larÄ± sakla
            results[arch] = {
                'predictor': predictor,
                'metrics': metrics,
                'predictions': predictions,
                'history': history.history if history else None
            }
            
            self.models[arch] = predictor
            
            print(f"âœ… {arch} modeli tamamlandÄ± - MAE: {metrics['mae']:.2f} kg")
        
        return results
    
    def create_ensemble_model(self, results):
        """En iyi modelleri birleÅŸtirerek ensemble oluÅŸtur"""
        print("ğŸ¯ Ensemble model oluÅŸturuluyor...")
        
        # Model performanslarÄ±na gÃ¶re aÄŸÄ±rlÄ±k hesapla
        weights = {}
        total_inverse_mae = 0
        
        for arch, result in results.items():
            mae = result['metrics']['mae']
            inverse_mae = 1 / mae
            weights[arch] = inverse_mae
            total_inverse_mae += inverse_mae
        
        # Normalize et
        for arch in weights:
            weights[arch] = weights[arch] / total_inverse_mae
        
        print("ğŸ“Š Model aÄŸÄ±rlÄ±klarÄ±:")
        for arch, weight in weights.items():
            print(f"   {arch}: {weight:.3f}")
        
        # Ensemble oluÅŸtur
        ensemble = ModelEnsemble()
        for arch, result in results.items():
            ensemble.add_model(result['predictor'], weights[arch])
        
        return ensemble, weights
    
    def evaluate_ensemble(self, ensemble, data):
        """Ensemble modelini deÄŸerlendir"""
        print("ğŸ† Ensemble model deÄŸerlendiriliyor...")
        
        X_test, y_test, _ = data['test']
        
        # Ensemble tahminleri
        y_pred_ensemble = ensemble.predict(X_test)
        
        # Metrikler hesapla
        mse = np.mean((y_test - y_pred_ensemble.flatten()) ** 2)
        mae = np.mean(np.abs(y_test - y_pred_ensemble.flatten()))
        mape = np.mean(np.abs((y_test - y_pred_ensemble.flatten()) / y_test)) * 100
        
        ss_res = np.sum((y_test - y_pred_ensemble.flatten()) ** 2)
        ss_tot = np.sum((y_test - np.mean(y_test)) ** 2)
        r2_score = 1 - (ss_res / ss_tot)
        
        ensemble_metrics = {
            'mse': mse,
            'mae': mae,
            'mape': mape,
            'r2_score': r2_score,
            'rmse': np.sqrt(mse)
        }
        
        print(f"ğŸŠ Ensemble PerformansÄ±:")
        print(f"   MAE: {ensemble_metrics['mae']:.2f} kg")
        print(f"   RMSE: {ensemble_metrics['rmse']:.2f} kg") 
        print(f"   MAPE: {ensemble_metrics['mape']:.2f}%")
        print(f"   RÂ² Score: {ensemble_metrics['r2_score']:.4f}")
        
        return ensemble_metrics, y_pred_ensemble
    
    def plot_training_results(self, results):
        """EÄŸitim sonuÃ§larÄ±nÄ± gÃ¶rselleÅŸtir"""
        print("ğŸ“ˆ EÄŸitim sonuÃ§larÄ± gÃ¶rselleÅŸtiriliyor...")
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # Loss grafikleri
        ax1 = axes[0, 0]
        for arch, result in results.items():
            if result['history']:
                ax1.plot(result['history']['loss'], label=f'{arch} - train')
                ax1.plot(result['history']['val_loss'], label=f'{arch} - val', linestyle='--')
        ax1.set_title('Model Loss')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True)
        
        # MAE grafikleri
        ax2 = axes[0, 1]
        for arch, result in results.items():
            if result['history']:
                ax2.plot(result['history']['mean_absolute_error'], label=f'{arch} - train')
                ax2.plot(result['history']['val_mean_absolute_error'], label=f'{arch} - val', linestyle='--')
        ax2.set_title('Mean Absolute Error')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('MAE')
        ax2.legend()
        ax2.grid(True)
        
        # Model karÅŸÄ±laÅŸtÄ±rmasÄ±
        ax3 = axes[1, 0]
        architectures = list(results.keys())
        mae_scores = [results[arch]['metrics']['mae'] for arch in architectures]
        r2_scores = [results[arch]['metrics']['r2_score'] for arch in architectures]
        
        x = np.arange(len(architectures))
        ax3.bar(x, mae_scores, alpha=0.7)
        ax3.set_title('Model MAE KarÅŸÄ±laÅŸtÄ±rmasÄ±')
        ax3.set_xlabel('Model')
        ax3.set_ylabel('MAE (kg)')
        ax3.set_xticks(x)
        ax3.set_xticklabels(architectures)
        
        # RÂ² skorlarÄ±
        ax4 = axes[1, 1]
        ax4.bar(x, r2_scores, alpha=0.7, color='green')
        ax4.set_title('Model RÂ² Skoru KarÅŸÄ±laÅŸtÄ±rmasÄ±')
        ax4.set_xlabel('Model')
        ax4.set_ylabel('RÂ² Score')
        ax4.set_xticks(x)
        ax4.set_xticklabels(architectures)
        
        plt.tight_layout()
        plt.savefig('training_results.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("ğŸ’¾ Grafikler 'training_results.png' olarak kaydedildi")
    
    def generate_model_report(self, results, ensemble_metrics):
        """DetaylÄ± model raporu oluÅŸtur"""
        print("ğŸ“‹ Model raporu oluÅŸturuluyor...")
        
        report = {
            'training_summary': {
                'total_models': len(results),
                'architectures': list(results.keys()),
                'best_individual_model': min(results.keys(), key=lambda x: results[x]['metrics']['mae']),
                'ensemble_improvement': True
            },
            'individual_models': {},
            'ensemble_performance': ensemble_metrics,
            'recommendations': []
        }
        
        # Bireysel model sonuÃ§larÄ±
        for arch, result in results.items():
            report['individual_models'][arch] = result['metrics']
        
        # En iyi modeli bul
        best_model = report['training_summary']['best_individual_model']
        best_mae = results[best_model]['metrics']['mae']
        ensemble_mae = ensemble_metrics['mae']
        
        # Ã–neriler
        if ensemble_mae < best_mae:
            improvement = ((best_mae - ensemble_mae) / best_mae) * 100
            report['recommendations'].append(f"Ensemble model %{improvement:.1f} daha iyi performans gÃ¶steriyor")
        
        if ensemble_metrics['r2_score'] > 0.9:
            report['recommendations'].append("Model Ã§ok iyi performans gÃ¶steriyor (RÂ² > 0.9)")
        elif ensemble_metrics['r2_score'] > 0.8:
            report['recommendations'].append("Model iyi performans gÃ¶steriyor (RÂ² > 0.8)")
        else:
            report['recommendations'].append("Model performansÄ± geliÅŸtirilebilir")
        
        # Raporu kaydet
        with open('model_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print("ğŸ“„ Model raporu 'model_report.json' olarak kaydedildi")
        return report

def main():
    """Ana eÄŸitim pipeline'Ä±"""
    print("ğŸš€ Hibrit AI Model EÄŸitim Pipeline'Ä± BaÅŸlatÄ±lÄ±yor")
    print("=" * 60)
    
    # Pipeline oluÅŸtur
    pipeline = TrainingPipeline()
    
    # Veriyi yÃ¼kle
    data = pipeline.load_processed_data()
    
    # Birden fazla model eÄŸit
    results = pipeline.train_multiple_models(data)
    
    # Ensemble oluÅŸtur
    ensemble, weights = pipeline.create_ensemble_model(results)
    
    # Ensemble'Ä± deÄŸerlendir
    ensemble_metrics, _ = pipeline.evaluate_ensemble(ensemble, data)
    
    # SonuÃ§larÄ± gÃ¶rselleÅŸtir
    pipeline.plot_training_results(results)
    
    # Rapor oluÅŸtur
    report = pipeline.generate_model_report(results, ensemble_metrics)
    
    print("\nğŸ‰ EÄŸitim tamamlandÄ±!")
    print(f"ğŸ† En iyi bireysel model: {report['training_summary']['best_individual_model']}")
    print(f"ğŸ¯ Ensemble MAE: {ensemble_metrics['mae']:.2f} kg")
    print(f"ğŸ“Š Ensemble RÂ²: {ensemble_metrics['r2_score']:.4f}")
    
    return pipeline, results, ensemble

if __name__ == "__main__":
    pipeline, results, ensemble = main() 